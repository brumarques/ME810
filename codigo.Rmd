---
title: "Validari - Linearidade"
author: "Estatística 2017"
date: "11 de setembro de 2017"
output:
  html_document: default
  pdf_document: default
header-includes: \usepackage{bbm}
---

# Introdução

<p align="justify"> $\quad$ A Validari é uma start up criada com o intuito de auxiliar os laboratórios farmacêuticos na validação de métodos analíticos. A proposta da empresa é criar um software online, que seja capaz de validar métodos analíticos de forma ágil e correta estatisticamente.  
 $\quad$ Resultados analíticos não confiáveis podem conduzir a decisões erradas e prejuízos financeiros irreparáveis, por isso a importância de validar de forma correta os métodos analíticos. Essa validação é dividida em etapas, existem vários critérios que precisam ser satisfeitos para que o método seja validado. Dentre esses critérios está a Linearidade, que corresponde à capacidade do método em fornecer resultados diretamente proporcionais à concentração do analito em amostras, dentro de uma determinada faixa de concentração. Todos os cálculos para a avaliação da Linearidade devem ser realizados a partir dos dados de concentrações reais e as respostas analíticas individuais (“Área”).
$\quad$	A Agência Nacional de Vigilância Sanitária (Anvisa) possui normas com sugestões de análises para cada critério da validação de métodos analíticos. Porém, algumas sugestões são muito subjetivas, dificultando o trabalho de validação.
 	$\quad$ Por isso, o objetivo do nosso projeto é avaliar e revisar a metodologia estatística usada para validação da Linearidade, explicando de forma clara o passo a passo da metodologia mais adequada. Todas as análises, gráficos e tabelas foram feitos no software R.</p>  


# Análise Descritiva   

<p align="justify"> $\quad$ Quando se tem um conjunto de dados, a análise descritiva é o primeiro passo que deve ser feito, pois fornece resumos simples sobre a amostra e sobre as variáveis observadas. Tal resumo pode ser quantitativo ou visual, com tabelas, gráficos e figuras. Para exemplificar a análise descritiva e a metodologia estatística adequada, vamos utilizar um conjunto de dados disponível em: http://www.portalaction.com.br/validacao-de-metodologia-analitica/112-linearidade, as observações são da concentração de um analito em uma amostra e sua respectiva área. 
$\quad$ Como no caso de validação de métodos analíticos as variáveis são “concentração” e “área”, sabemos que ambas são positivas e não nulas, ou seja, maiores que zero. Sugerimos então, fazer um gráfico de dispersão e calcular as medidas resumo para começar a entender melhor como os dados se comportam.
$\quad$ Pelo gráfico de dispersão (Figura 1), é possível observar como é a relação entre as duas variáveis, se há valores discrepantes ou se há alguma inconsistência nos dados (erro de digitação, por exemplo). Pelas medidas resumo (Tabela 1), verificamos se os valores tem as características esperadas. Tais medidas consistem em valores máximo e mínimo, média e desvio padrão, para cada uma das variáveis. 
$\quad$ Se houver suspeita de que algum valor não esteja correto, deve-se realizar uma análise mais aprofundada para confirmar, lembrando que não devemos retirar um valor da amostra, por mais que ele seja muito diferente dos demais, exceto quando há certeza de que foi um erro humano ou falha do equipamento.</p>

```{r, echo=FALSE, warning=FALSE,fig.align='center'}
library(readxl) #biblioteca para ler o excel
library(knitr)
library(ggplot2)
data <- read_excel("C:/Users/Bruna Marques/Desktop/ME810-master/data.xlsx") #leitura dos dados
#plot(data, main="Gráfico de Dispersão", xlab="Concentração", ylab="Área") #grafico de dispersao
ggplot(data, aes(x=data[,1], y=data[,2])) + geom_point(size=3) + labs(title="Associação entre Área e Concentração",x="Concentração", y = "Área") + theme_bw()

```

<center>Figura 1: O gráfico de dispersão utiliza coordenadas cartesianas para exibir valores do conjunto de dados. Os dados são exibidos como uma coleção de pontos, cada um com os valores observados da “Concentração” determinando a posição no eixo horizontal e o valor da “Área” determinando a posição no eixo vertical . Por exemplo, vemos que para uma área de 8560 observamos  uma concentração de 0,24.</center> 

<center>Tabela 1: Medidas resumo do conjunto de dados. Máximo e Mínimo corresponde ao maior e ao menor valor observado, respectivamente, em relação à cada variável. A Média é a média aritmética das observações de cada variável, e por fim o Desvio Padrão é uma medida de dispersão em torno da Média.</center> 

|        | Concentração | Área     |
|--------|---:|---:|
| Mínimo | `r min(data$Concentração)` | `r formatC(min(data$Área), digits = 6)`  |
| Máximo | `r max(data$Concentração)` | `r formatC(max(data$Área), digits = 7)`  |
| Média  | `r mean(data$Concentração)`| `r formatC(mean(data$Área), digits = 7)` |
| Desvio Padrão  | `r round(sd(data$Concentração),2)`| `r formatC(sd(data$Área), digits = 6)` |

# Regressão Linear e Significância dos Parâmetros (Curva Analítica)  

<p align="justify"> $\quad$ Estatisticamente, a melhor forma de avaliar a linearidade é através da regressão  linear, pois é a metodologia que estuda a relação entre uma variável resposta (Área) e outras variáveis (Concentração). Com a regressão, vemos qual a melhor reta $(y=ax+b)$ a ser traçada que se ajusta melhor nesses dados, ou seja, qual reta faz com que a distância entre os pontos e a reta ajustada seja a menor possível, minimizando o erro e estimando com maior precisão, por isso a estimação é feita através do Método dos Mínimos Quadrados.</p>  

```{r,echo=FALSE,fig.align='center', warning=FALSE}
fit = lm(Área ~ Concentração, data=data)
#plot(Área~Concentração, data=data, main="Curva Analítica")
#abline(fit, col="red")
r= summary(fit)$r.squared
ggplot(data, aes(x=data[,1], y=data[,2])) + geom_point(size=3) + labs(title="Associação entre Concentração e Área, com a reta ajustada",x="Concentração", y = "Área") +   geom_smooth(method=lm, se=FALSE,size=1)+ theme_bw()

```

<center>Figura 2: Figura 2: Gráfico de dispersão com a reta de regressão ajustada, que mostra a variável “Área” em função da “Concentração”. A reta de regressão passa em cima dos pontos.</center>\n  

<p align="justify"> $\quad$ Na Figura 2, temos a reta de regressão ajustada (curva analítica), podemos notar que os pontos se alinham bem a uma reta. A equação dessa reta é dada por:
$ Área = 515.12 + 33675.67 *Concentração $,
ou seja, $a= 33675.67$ e $b= 515.12$ O coeficiente de correlação obtido é $R^2 ≈1$, lembrando que a Anvisa sugere que o $R^2$ esteja acima de $0.990$ .


# Qualidade de Ajuste do Modelo

<p align="justify"> $\quad$ AApós determinarmos a metodologia e ajustarmos o modelo, é necessário verificar a qualidade do ajuste do modelo aos dados. Algumas técnicas podem ser utilizadas, dentre elas a “Análise de Variância da Regressão” (ANOVA), que é uma das mais utilizadas. 
  Considerando o nosso exemplo, o resultado da ANOVA é mostrado na Tabela 2.</p> 

| Parâmetro 	| Estimativa                                          	| p-valor                             	|
|-----------	|---:	|---:	|
| a         	| `r  format(coefficients(fit)[2], scientific=FALSE)` 	| `r round(summary(fit)$coefficients[2,4],1)`  	|
| b         	| `r round(coefficients(fit)[1], 2)`                  	| `r round(summary(fit)$coefficients[1,4],1)`  	|    

<center>Tabela 2: Tabela resultado da ANOVA - Estimativas e p-valor dos parâmetros da reta ajustada. </center> \n

<p align="justify"> $\quad$ PPara avaliar a significância dos parâmetros (a e b), ou seja, se eles são diferentes de zero, vamos observar o p-valor. Dado que o nível de significância sugerido pela Anvisa é 5%, se o p-valor for menor que 0.05 há evidências de que a concentração tem uma associação linear com a área, em um modelo cujo coeficiente angular é diferente de zero (lembrando que dentre as sugestões da Anvisa, o coeficiente angular deve ser significativamente diferente de zero). Para o nosso exemplo, os dois parâmetros são significativos, uma vez que o p-valor de ambos é menor que 0.05. </p>



# Diagnóstico do Modelo - Análise de Resíduos

<p align="justify"> $\quad$ O ajuste de uma reta de regressão é feito baseado em suposições teóricas. Para verificar se a reta de regressão ajustada satisfaz as suposições teóricas da metodologia estatística, devemos avaliar três suposições relacionadas ao resíduo. São elas: Independência, Homocedasticidade e Normalidade. Podemos fazer análises gráficas e também testes estatísticos específicos para cada uma delas,  para assim constatar se as três suposições são válidas. 
$\quad$ A independência pode ser confirmada, se no gráfico de resíduos versus ordem da coleta, os pontos estiverem distribuídos de forma aleatória em torno de zero e dentro dos limites, assim como na Figura 3. Podemos fazer também o teste Durbin-Watson, que é utilizado para detectar a presença de autocorrelação (dependência), representada por . Temos que os resíduos são independentes se, dada as hipóteses: </p> 
  
 $H_0: \rho  = 0$ vs $H_1: \rho  \neq  0$
  
  
não rejeitamos H0se o p-valor obtido for maior que o nível de significância, isso significa que não rejeitamos a hipótese de que a correlação é zero, ou seja, há evidências de independência. O p-valor encontrado foi de 0.3554, ou seja, temos evidências de que os resíduos são independentes, com nível de significância de 0.05. Já pelo gráfico da Figura 3, podemos observar que os pontos estão dispersos aleatoriamente, o que é mais uma evidência de que os resíduos são independentes.

 

```{r, echo=FALSE, warning=FALSE, results=FALSE}
#Teste de Durbin-Watson - Independencia
#library(lmtest)
#dwtest(fit)

```


```{r,echo=FALSE,fig.align='center'}
#plot(fit$fitted.values,residuals(fit),ylab="Resíduos",xlab="Valores ajustados"); abline(h=0)

ggplot(fit, aes(x=fit$fitted.values, y=fit$residuals)) + geom_point(size=2) + labs(x="Valores ajustados", y = "Resíduos") +
geom_hline(yintercept = 0, color="red")+ theme_bw()

```

<center>Figura 3: Gráfico de resíduos padronizados vs ordem de coleta.</center> \n


<p align="justify"> $\quad$ A segunda suposição a ser verificada é a homocedasticidade, isto é, se a variância dos resíduos é constante. Uma forma de fazer isso é gerando o gráfico de resíduos padronizados versus valores ajustados. 
Se os pontos estiverem distribuídos de forma aleatória, sem uma tendência de aumento ou diminuição de variabilidade, a homocedasticidade é satisfeita (Figura 4). Para complementar a análise, um teste estatístico que pode ser feito é o Teste de Cochran, que compara a maior variância com as demais. As hipóteses são dadas por: </p>


$H_0: \sigma^2 _1=\sigma^2_2=...=\sigma^2_k$ vs $H_1:$ pelo menos um $\sigma^2_i$ é diferente, $i=1,...k$


e do mesmo modo como teste anterior, os resíduos são homocedásticos se p-valor for maior que o nível de significância. O p-valor encontrado foi de 0.409, então há evidência estatística de que os resíduos do modelo são homocedásticos, a nível de 5% de significância. Ou seja, não detectamos diferença significativa entre as variâncias dos resíduos do modelo.

```{r,echo=FALSE,fig.align='center'}
respad <-rstandard(fit)
#plot(respad, xlab="Ordem de coleta",ylab="Resíduos Padronizados")
#lines(respad, lty=2)
#abline(h=0)
#abline(h=2,lty=2, col="blue")
#abline(h=-2,lty=2,col="blue")

x1<-c(1:30)
ggplot(fit, aes( x=x1,y=respad)) + 
  geom_point(size=2) + 
  labs(x="Ordem de coleta", y = "Resíduos Padronizados") +
  geom_hline(yintercept = 0, color="red") + 
  geom_hline(yintercept = 2, color="red",linetype="dashed") + 
  geom_hline(yintercept = -2, color="red",linetype="dashed")+ theme_bw()

```

<center>Figura 4: Gráfico de resíduos vs valores ajustados.</center> \n

```{r, echo=FALSE, warning=FALSE}
#Teste de Cochran - Homocedasticidade
#library(outliers)
#cochran.test(Área~Concentração, data)
```
 
 
<p align="justify"> $\quad$ Por fim, vamos verificar terceira suposição: a normalidade dos resíduos. Isso significa verificar se a distribuição de probabilidade associada ao conjunto de dados pode ser aproximada pela distribuição normal. Se os resíduos são normais, os pontos do gráfico devem estar próximos e em torno da reta, de forma aleatória, sem seguir nenhum padrão, como é mostrado na Figura 5. Um dos testes estatísticos mais conhecidos para verificar a normalidade é o Shapiro-Wilk, em que as hipóteses são: </p>

$H_0:$ A amostra vem de uma distribuição Normal vs $H_1:$ A amostra não vem de uma distribuição Normal


<p align="justify"> $\quad$ E assim chegamos em conclusões similares aos outros testes: como p-valor encontrado é 0.7476 e é maior que o nível de significância, temos evidência estatística de normalidade dos resíduos. </p>


```{r,echo=FALSE,fig.align='center'}
#qqnorm(residuals(fit),pch=20);qqline(residuals(fit))

qqplot.data <- function (vec) # argument: vector of numbers
{
  # following four lines from base R's qqline()
  y <- quantile(vec[!is.na(vec)], c(0.25, 0.75))
  x <- qnorm(c(0.25, 0.75))
  slope <- diff(y)/diff(x)
  int <- y[1L] - slope * x[1L]

  d <- data.frame(resids = vec)

  ggplot(d, aes(sample = resids)) + stat_qq() + geom_abline(slope = slope, intercept = int)+ theme_bw()

}
qqplot.data(residuals(fit))

```

<center>Figura 5: (QQ-plot) Gráfico de probabilidade para os resíduos do modelo linear simples ajustado.</center> \n


```{r, echo=FALSE, warning=FALSE}
#Teste de Shapiro Wilk - Normalidade
#shapiro.test(fit$residuals)
```

<p align="justify"> $\quad$ Se alguma das suposições acima não ocorrer, a linearidade não é satisfeita, uma vez que as suposições teóricas para ajuste da reta não são válidas. Para o nosso exemplo, a linearidade é satisfeita, uma vez que a reta está bem ajustada e os resíduos satisfazem as suposições do modelo de regressão, e também para todos os testes o p-valor foi maior que o nível de significância estabelecido. Um outro teste que complementa a avaliação do modelo de regressão é o Teste da Falta de Ajuste, que verifica se o modelo linear é adequado para o conjunto de dados ou não, testando as seguintes hipóteses: </p>


$H_0:$ Modelo linear é adequado         vs $H_1:$ Modelo linear não é adequado


<p align="justify"> $\quad$ Este teste assume que a normalidade, independência e homocedasticidade dos resíduos sejam satisfeitas (o que é válido no nosso exemplo). Assim, após o ajuste e análise de resíduos, é importante verificar se o modelo linear é adequado. Como podemos ver na Tabela 3, o p-valor encontrado para a falta de ajuste foi 0.7676, sendo é maior que o nível de significância 0.05, ou seja, como não rejeita-se H0, há evidências de que o modelo linear é adequado para esse conjunto de dados. </p>


```{r,echo=FALSE, warning=FALSE }
library(alr3)
#pureErrorAnova(fit)
```

Tabela 3: Resultados do Teste de Falta de Ajuste.

|                  | Teste de Falta de Ajuste |         |
|---:|---:|---:|
|                  |       Estatística        | P-valor |
|   Concentração   |              07.3965e+08 | <0.0001 |
| Falta de ajuste  |               3.8090e-01 |  0.7676 |


 

# Conclusão

<p align="justify"> $\quad$ Através de métodos estatísticos temos condição de validar a Linearidade. Partindo inicialmente com uma análise descritiva, podemos ter uma visão geral dos dados e verificar se há possíveis pontos aberrante (outliers), erro da amostra, erro de digitação ou alguma inconsistência. Seguindo com uma análise de regressão linear, com o objetivo de traçar uma reta que matematicamente interpreta os pontos amostrados, essa reta denomidada de curva analítca possui um coeficiente linear que também foi calculado conforme é pedido pelas normas de validação da Linearidade pelo nosso país. 
$\quad$ Por fim, é feita uma análise para verificar a qualidade desta curva e se ela de fato pode ser utilizada para representar a amostra, o que inclui os testes para verificação de independência, normalidade e homocedasticidade dos resíduos do modelo. A análise dos gráficos é de certa forma subjetiva, por isso cada conjunto de dados deverá ser analisado por um avaliador experiente e ele quem deverá fazer as devidas conclusões. Já para as análises que possuem p-valor, após um nível de significância pré definido, o resultado será obtido diretamente.
	$\quad$ Os códigos computacionais no software R podem ser acessados no link:
https://github.com/brumarques/ME810 - arquivo “codigo.Rmd” </p> 

